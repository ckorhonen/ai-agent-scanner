# AI Agent Readiness Scanner

**Is your website ready for AI agents?**

A free, open-source tool that scores websites on how well they work with AI agents â€” WebMCP support, semantic HTML, structured data, llms.txt, crawlability, and more. Get a grade, a readiness level, and a prioritised fix list in seconds.

ğŸŒ **Live:** [scanner.v1be.codes](https://scanner.v1be.codes)

---

## What It Checks (100 points)

| Category | Max | What's Measured |
|---|---|---|
| âš¡ Agent Usability | 30 | Form labels, semantic buttons, CAPTCHA walls, login friction, pagination |
| ğŸ¤– WebMCP Support | 25 | `mcp-tool`, `mcp-param`, `mcp-description` attrs; OpenAPI / `ai-plugin.json` |
| ğŸ—ï¸ Semantic HTML | 20 | HTML5 landmarks, heading hierarchy, `lang` attr, ARIA roles, div-soup ratio |
| ğŸ“Š Structured Data | 15 | JSON-LD blocks, rich Schema.org types (Product, FAQ, SearchActionâ€¦) |
| ğŸ” AI Discoverability | 5 | HTTPS, `robots.txt`, `sitemap.xml`, **`llms.txt`** (844k+ sites adopting) |
| ğŸ“ Content Quality | 5 | Image alt text coverage, link descriptiveness |

### The 5 Readiness Levels

| Level | Range | Label | Meaning |
|---|---|---|---|
| ğŸ”´ 1 | 0â€“20 | Invisible | AI agents can't meaningfully access the site |
| ğŸŸ  2 | 21â€“40 | Crawlable | Agents can read text but not understand structure |
| ğŸŸ¡ 3 | 41â€“60 | Discoverable | Structured data helps agents understand content |
| ğŸŸ¢ 4 | 61â€“80 | Operable | Agents can navigate and take actions |
| ğŸ”µ 5 | 81â€“100 | AI-Native | Full WebMCP, llms.txt, agent-optimised â€” top ~3% of the web |

---

## Features

- **Free, no login** â€” scan any public URL instantly
- **Competitor comparison** â€” scan up to 4 sites side-by-side
- **Per-check detail** â€” every failed check shows exactly what's wrong and how to fix it, with copy-paste code examples
- **Educational notes** â€” each category explains *why* it matters for AI agents
- **Natural language summary** â€” plain-English interpretation of your score
- **"Path to next grade" banner** â€” shows the lowest-effort fixes to reach the next letter grade
- **Share button** â€” copy the scan URL to share results
- **Response time badge** â€” flags slow pages that frustrate agents
- **robots.txt + sitemap.xml** â€” the scanner itself is agent-ready

---

## Tech Stack

- **Runtime:** [Cloudflare Workers](https://workers.cloudflare.com/) via [Cloudflare Pages](https://pages.cloudflare.com/)
- **Framework:** [Remix](https://remix.run/) (SSR, loader-based scanning)
- **Styling:** [Tailwind CSS](https://tailwindcss.com/)
- **Deployment:** `wrangler pages deploy` with custom `_worker.js` entry

### Architecture

```
Request â†’ Cloudflare Pages (_worker.js)
  â”œâ”€â”€ Static assets (/assets/*) â†’ ASSETS binding (direct serve)
  â””â”€â”€ Dynamic routes â†’ Remix createRequestHandler
        â”œâ”€â”€ GET /           â†’ Landing page
        â”œâ”€â”€ GET /scan?url=â€¦ â†’ Parallel scanner execution
        â”‚     â”œâ”€â”€ analyzers/usability.ts
        â”‚     â”œâ”€â”€ analyzers/webmcp.ts
        â”‚     â”œâ”€â”€ analyzers/semantic.ts
        â”‚     â”œâ”€â”€ analyzers/schema.ts
        â”‚     â”œâ”€â”€ analyzers/crawlability.ts   â† HTTP fetches: robots.txt, sitemap, llms.txt
        â”‚     â””â”€â”€ analyzers/content.ts
        â”œâ”€â”€ GET /robots.txt â†’ Dynamic robots.txt
        â””â”€â”€ GET /sitemap.xml â†’ Dynamic sitemap
```

---

## Development

```bash
# Install
npm install

# Dev server (localhost:5173)
npm run dev

# Production build
npm run build

# Deploy to Cloudflare Pages
npm run build
node_modules/.bin/esbuild worker-entry.js \
  --bundle --platform=browser --target=esnext --format=esm \
  --external:__STATIC_CONTENT_MANIFEST \
  --conditions=worker,browser \
  --outfile=build/client/_worker.js

CLOUDFLARE_API_TOKEN=<token> CLOUDFLARE_ACCOUNT_ID=<account> \
  npx wrangler pages deploy build/client \
  --project-name ai-agent-scanner \
  --no-bundle
```

### Key Files

```
app/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ types.ts          # ScanResult, CategoryDetail, ReadinessLevel interfaces
â”‚   â”œâ”€â”€ scanner.ts        # Orchestrates all analyzers â†’ ScanResult
â”‚   â”œâ”€â”€ scoring.ts        # Grade/level calculation, generateRecommendations()
â”‚   â””â”€â”€ analyzers/
â”‚       â”œâ”€â”€ usability.ts  # Form labels, buttons, CAPTCHA, pagination
â”‚       â”œâ”€â”€ webmcp.ts     # WebMCP attribute detection
â”‚       â”œâ”€â”€ semantic.ts   # HTML5 landmarks, headings, ARIA, lang attr
â”‚       â”œâ”€â”€ schema.ts     # JSON-LD, microdata, rich types
â”‚       â”œâ”€â”€ crawlability.ts # robots.txt, sitemap, llms.txt, HTTPS
â”‚       â””â”€â”€ content.ts    # Alt text, link quality
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ _index.tsx        # Landing page (educational + scan form)
â”‚   â”œâ”€â”€ scan.tsx          # Results page (grade ring, category cards, recs)
â”‚   â”œâ”€â”€ robots[.]txt.ts   # Dynamic robots.txt
â”‚   â””â”€â”€ sitemap[.]xml.ts  # Dynamic sitemap
â””â”€â”€ root.tsx              # HTML shell, SEO meta, JSON-LD structured data
```

---

## Adding a New Check

1. Find the right analyzer in `app/lib/analyzers/`
2. Add a `CheckResult` to the `checks` array with `name`, `passed`, `impact`, `detail`, `fix`, and optionally `example`
3. Adjust `score` within the category's max (check `app/lib/scanner.ts` for maxes)
4. Optionally add a `Recommendation` in `app/lib/scoring.ts` â†’ `generateRecommendations()`

```ts
// Example check in semantic.ts
const hasLang = /html[^>]+lang=["'][a-z]/i.test(html)
if (!hasLang) score -= 2
checks.push({
  name: 'Language attribute (lang="â€¦")',
  passed: hasLang,
  impact: 'medium',
  detail: hasLang ? 'â€¦' : 'No lang attr â€” NLP models must guess the language',
  fix: 'Add lang="en" to your <html> element',
  example: '<html lang="en">',
})
```

---

## Contributing

PRs welcome. Things that would make this better:

- [ ] More WebMCP checks (mcp-endpoint, mcp-auth detection)
- [ ] `llms-full.txt` detection (verbose variant)
- [ ] Performance/Core Web Vitals via headless fetch timing
- [ ] JSON Feed / RSS detection (agents love structured content feeds)
- [ ] OpenGraph completeness scoring
- [ ] Shareable OG image generation per scan result
- [ ] Historical score tracking (D1 database)

---

## License

[MIT](./LICENSE) â€” Chris Korhonen

---

## See Also

- [WebMCP specification](https://webmcp.ai)
- [llmstxt.org](https://llmstxt.org) â€” The llms.txt community standard
- [Schema.org](https://schema.org) â€” Structured data vocabulary
- [v1be.codes](https://v1be.codes) â€” More experiments
